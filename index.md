---
layout: homepage
---

I am now at Bloomberg AI in New York! Please reach out if you'd like to know more about what we do. 

Previously, I spent five wonderful years at Carnegie Mellon University, working towards my PhD in Machine Learning under the guidance of [Aaditya Ramdas](http://stat.cmu.edu/~aramdas/){:target="_blank"}. My research was awarded a [Bloomberg Data Science Fellowship](https://www.techatbloomberg.com/bloomberg-data-science-ph-d-fellowship/){:target="_blank"}. The dissertation, titled "Post-hoc calibration without distributional assumptions", can be found [here](https://aigen.github.io/files/thesis.pdf){:target="_blank"}. Earlier, I was a Research Fellow at Microsoft Research, India with [Prateek Jain](http://www.prateekjain.org/){:target="_blank"}. I did my undergrad (B. Tech) in Computer Science at [IIT Kanpur](http://www.iitk.ac.in/){:target="_blank"}.  

## Publications and preprints
(in reverse chronological order of first preprint)

- **Parity Calibration**
  <br>
  Youngseog Chung, Aaron Rumack, Chirag Gupta
  <br>
  **UAI 2023 (oral)**. [[arxiv](https://arxiv.org/abs/2305.18655){:target="_blank"}] 

- **Online Platt Scaling with Calibeating**
  <br>
  Chirag Gupta, Aaditya Ramdas
  <br>
  **ICML 2023**. [[arxiv](https://arxiv.org/abs/2305.00070){:target="_blank"}] 


- **Faster online calibration without randomization: interval forecasts and the power of two choices**
  <br>
  Chirag Gupta, Aaditya Ramdas
  <br>
  **COLT 2022**. [[proc](https://proceedings.mlr.press/v178/gupta22b.html){:target="_blank"}] [[arxiv](https://arxiv.org/abs/2204.13087){:target="_blank"}] 


- **Top-label calibration and multiclass-to-binary reductions**
  <br>
  Chirag Gupta, Aaditya Ramdas
  <br>
  **ICLR 2022**. [[proc](https://openreview.net/forum?id=WqoBaaPHS-){:target="_blank"}] [[arxiv](http://arxiv.org/abs/2107.08353){:target="_blank"}] [[code](https://github.com/aigen/df-posthoc-calibration){:target="_blank"}] 

- **Distribution-free calibration guarantees for histogram binning without sample splitting**
  <br>
  Chirag Gupta, Aaditya Ramdas
  <br>
  **ICML 2021**.
  [[arxiv](https://arxiv.org/abs/2105.04656){:target="_blank"}] [[proc](http://proceedings.mlr.press/v139/gupta21b.html){:target="_blank"}] [[code](https://github.com/aigen/df-posthoc-calibration){:target="_blank"}] [[talk (from 37' to 50')](https://drive.google.com/file/d/1gWxE9osT-LaLoODE9nUyRK7990JbiD7o/view){:target="_blank"}]

- **Distribution-free binary classification: prediction sets, confidence intervals and calibration**
  <br>
  Chirag Gupta\*, Aleksandr Podkopaev\*, Aaditya Ramdas
  <br>
  **Neurips 2020  (spotlight)**.
  [[arxiv](https://arxiv.org/abs/2006.10564){:target="_blank"}] [[proc](https://proceedings.neurips.cc/paper/2020/hash/26d88423fc6da243ffddf161ca712757-Abstract.html){:target="_blank"}] [[talk (from 24' to 38')](https://drive.google.com/file/d/1gWxE9osT-LaLoODE9nUyRK7990JbiD7o/view){:target="_blank"}] [](Older version: https://www.youtube.com/watch?v=tWGb_4_jVao){:target="_blank"}

- **Nested conformal prediction and quantile out-of-bag ensemble methods**
  <br>
  Chirag Gupta, Arun K Kuchibhotla, Aaditya Ramdas
  <br>
  **Pattern Recognition (Special Issue on Conformal Prediction) 2022**.
  [[journal](https://www.sciencedirect.com/science/article/pii/S0031320321006725){:target="_blank"}] [[arxiv](https://arxiv.org/abs/1910.10562){:target="_blank"}] [[code](https://github.com/AIgen/QOOB){:target="_blank"}] [[talk (from 3' to 24')](https://drive.google.com/file/d/1gWxE9osT-LaLoODE9nUyRK7990JbiD7o/view){:target="_blank"}] [](Older version: https://www.youtube.com/watch?v=91B_a5baDyA)

- **Path length bounds for gradient descent and flow**
  <br>
  Chirag Gupta, Sivaraman Balakrishnan, Aaditya Ramdas
  <br>
  **Journal of Machine Learning Research (JMLR) 2021**.
  [[journal](https://jmlr.org/papers/v22/19-979.html){:target="_blank"}] [[arxiv](https://arxiv.org/abs/1908.01089){:target="_blank"}] [[blog](https://blog.ml.cmu.edu/2019/10/25/path-length-bounds-for-gradient-descent/){:target="_blank"}]

- **Support recovery for orthogonal matching pursuit: upper and lower bounds**
  <br>
  Raghav Somani\*, Chirag Gupta\*, Prateek Jain, Praneeth Netrapalli
  <br>
  **Neurips 2018 (spotlight)**.
  [[proc](https://proceedings.neurips.cc/paper/2018/hash/84b64e537f08e81b8dea8cce972a28b2-Abstract.html){:target="_blank"}]

- **Protonn: Compressed and accurate knn for resource-scarce devices**
  <br>
  Chirag Gupta, Arun Sai Suggala, Ankit Goyal, Harsha Vardhan Simhadri, Bhargavi Paranjape, Ashish Kumar, Saurabh Goyal, Raghavendra Udupa, Manik Varma, Prateek Jain
  <br>
  **ICML 2017**.
  [[proc](http://proceedings.mlr.press/v70/gupta17a.html){:target="_blank"}] [[code](https://github.com/Microsoft/EdgeML){:target="_blank"}] 


## Invited talks

- Provably calibrating ML classifiers without distributional assumptions (TrustML Young Scientist Seminar, September 2022) [[link](https://www.youtube.com/watch?v=4moQRDv8MGM){:target="_blank"}]
- Recent advances in distribution-free uncertainty quantification (International Seminar on Selective Inference, May 2021) [[link](https://drive.google.com/file/d/1gWxE9osT-LaLoODE9nUyRK7990JbiD7o/view){:target="_blank"}]

## Academic service

- Reviewer: ICML 2020, ALT 2020, Neurips 2021, ICML 2022, JMLR
- TA: Mathematical and Computational Foundations for ML (CMU), Machine Learning, Ethics, and Society (CMU)
